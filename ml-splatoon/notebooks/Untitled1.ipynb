{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 23:37:55,539 - kedro.io.data_catalog - INFO - Loading data from `train` (CSVDataSet)...\n",
      "2020-10-01 23:37:55,728 - kedro.io.data_catalog - INFO - Loading data from `test` (CSVDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 23:37:55,818 - kedro.io.data_catalog - INFO - Loading data from `stagedata` (CSVDataSet)...\n",
      "2020-10-01 23:37:55,820 - kedro.io.data_catalog - INFO - Loading data from `weapon` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "df_train = catalog.load(\"train\")\n",
    "df_test = catalog.load(\"test\")\n",
    "df_stage = catalog.load(\"stagedata\")\n",
    "df_weapon = catalog.load(\"weapon\")\n",
    "\n",
    "\n",
    "players = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['mode', 'stage', 'A1-weapon', 'A2-weapon','A3-weapon','A4-weapon',\n",
    "          'B1-weapon', 'B2-weapon','B3-weapon','B4-weapon']\n",
    "te_cat_cols = ['A1-mainweapon', 'A1-subweapon', 'A1-special', 'A1-category',\n",
    "              'A2-mainweapon', 'A2-subweapon', 'A2-special', 'A2-category',\n",
    "              'A3-mainweapon', 'A3-subweapon', 'A3-special', 'A3-category',\n",
    "              'A4-mainweapon', 'A4-subweapon', 'A4-special', 'A4-category',\n",
    "              'B1-mainweapon', 'B1-subweapon', 'B1-special', 'B1-category',\n",
    "              'B2-mainweapon', 'B2-subweapon', 'B2-special', 'B2-category',\n",
    "              'B3-mainweapon', 'B3-subweapon', 'B3-special', 'B3-category',\n",
    "              'B4-mainweapon', 'B4-subweapon', 'B4-special', 'B4-category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_to_value(x):\n",
    "    rank = {'c-': 1, 'c': 2, 'c+': 3,\n",
    "            'b-': 4, 'b': 5, 'b+': 6,\n",
    "            'a-': 7, 'a': 8, 'a+': 9,\n",
    "            's': 10, 's+': 11, 'x': 12\n",
    "            }\n",
    "    if x in rank:\n",
    "        x = rank[x]\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_average(x, team):\n",
    "    x[f\"{team}-rank-ave\"] = (x[f\"{team}1-rank\"] + x[f\"{team}2-rank\"] + x[f\"{team}3-rank\"] + x[f\"{team}4-rank\"]) / 4\n",
    "    return x[f\"{team}-rank-ave\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot_encoder(x):\n",
    "    import category_encoders as ce\n",
    "    list_cols = ['mode', 'stage']\n",
    "    ce_ohe = ce.OneHotEncoder(cols=list_cols, handle_unknown='impute')\n",
    "    return ce_ohe.fit_transform(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(train_x, train_y, test_x, cat_cols):\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    for c in cat_cols:\n",
    "        data_tmp = pd.DataFrame({c: train_x[c], 'target': train_y})\n",
    "        target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "        \n",
    "        test_x[c] = test_x[c].map(target_mean)\n",
    "        \n",
    "        tmp = np.repeat(np.nan, train_x.shape[0])\n",
    "        \n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=1234)\n",
    "        \n",
    "        for idx_1, idx_2 in kf.split(train_x):\n",
    "            target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
    "            tmp[idx_2] = train_x[c].iloc[idx_2].map(target_mean)\n",
    "        train_x[c] = tmp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def level_average(x, team):\n",
    "    x[f\"{team}-level-ave\"] = (x[f\"{team}1-level\"] + x[f\"{team}2-level\"] + x[f\"{team}3-level\"] + x[f\"{team}4-level\"]) / 4\n",
    "    return x[f\"{team}-level-ave\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(data):\n",
    "    import random\n",
    "    temp_data = data.copy()\n",
    "    temp_data = temp_data.dropna()\n",
    "    A_team = [\"A1\", \"A2\", \"A3\", \"A4\"]\n",
    "    B_team = [\"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "    for index, row in temp_data.iterrows():\n",
    "        rand_A = random.sample(A_team, 4)\n",
    "        temp_data.at[index,\"A1-weapon\"], temp_data.at[index,\"A2-weapon\"], temp_data.at[index,\"A3-weapon\"], temp_data.at[index,\"A4-weapon\"] = \\\n",
    "            row[f\"{rand_A[0]}-weapon\"], row[f\"{rand_A[1]}-weapon\"], row[f\"{rand_A[2]}-weapon\"], row[f\"{rand_A[3]}-weapon\"]\n",
    "        temp_data.at[index,\"A1-rank\"], temp_data.at[index,\"A2-rank\"], temp_data.at[index,\"A3-rank\"], temp_data.at[index,\"A4-rank\"] = \\\n",
    "            row[f\"{rand_A[0]}-rank\"], row[f\"{rand_A[1]}-rank\"], row[f\"{rand_A[2]}-rank\"], row[f\"{rand_A[3]}-rank\"]\n",
    "        temp_data.at[index,\"A1-level\"], temp_data.at[index,\"A2-level\"], temp_data.at[index,\"A3-level\"], temp_data.at[index,\"A4-level\"] = \\\n",
    "            row[f\"{rand_A[0]}-level\"], row[f\"{rand_A[1]}-level\"], row[f\"{rand_A[2]}-level\"], row[f\"{rand_A[3]}-level\"]\n",
    "\n",
    "        rand_B = random.sample(B_team, 4)\n",
    "        temp_data.at[index,\"B1-weapon\"], temp_data.at[index,\"B2-weapon\"], temp_data.at[index,\"B3-weapon\"], temp_data.at[index,\"B4-weapon\"] = \\\n",
    "            row[f\"{rand_B[0]}-weapon\"], row[f\"{rand_B[1]}-weapon\"], row[f\"{rand_B[2]}-weapon\"], row[f\"{rand_B[3]}-weapon\"]\n",
    "        temp_data.at[index,\"B1-rank\"], temp_data.at[index,\"B2-rank\"], temp_data.at[index,\"B3-rank\"], temp_data.at[index,\"B4-rank\"] = \\\n",
    "            row[f\"{rand_B[0]}-rank\"], row[f\"{rand_B[1]}-rank\"], row[f\"{rand_B[2]}-rank\"], row[f\"{rand_B[3]}-rank\"]\n",
    "        temp_data.at[index,\"B1-level\"], temp_data.at[index,\"B2-level\"], temp_data.at[index,\"B3-level\"], temp_data.at[index,\"B4-level\"] = \\\n",
    "            row[f\"{rand_B[0]}-level\"], row[f\"{rand_B[1]}-level\"], row[f\"{rand_B[2]}-level\"], row[f\"{rand_B[3]}-level\"]\n",
    "    data = pd.concat([data, temp_data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weapon(weapon):\n",
    "    weapon[\"category\"] = weapon[\"category2\"]\n",
    "    weapon = weapon.drop([\"category1\", \"category2\"], axis=1)\n",
    "    return weapon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stage(stagedata):\n",
    "    return stagedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test, stagedata):\n",
    "    train = data_augmentation(train)\n",
    "    target = train['y']\n",
    "    data = pd.concat([train, test])\n",
    "    \n",
    "    players = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "    data = data.join(stagedata.set_index(\"stage\"), on=\"stage\")\n",
    "    \n",
    "    for player in players:\n",
    "        data[f\"{player}-rank\"] = data[f\"{player}-rank\"].apply(rank_to_value)\n",
    "        data[f\"{player}-weapon\"] = data[f\"{player}-weapon\"].fillna(\"Nothing\")\n",
    "        data[f\"{player}-level\"] = data[f\"{player}-level\"].fillna(0)\n",
    "    data[\"A-rank-ave\"] = rank_average(data, \"A\")\n",
    "    data[\"B-rank-ave\"] = rank_average(data, \"B\")\n",
    "    data[\"A-level-ave\"] = level_average(data, \"A\")\n",
    "    data[\"B-level-ave\"] = level_average(data, \"B\")\n",
    "    data = OneHot_encoder(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "target = data_augmentation(df_train)['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "processed_weapon = preprocess_weapon(df_weapon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stage = preprocess_stage(df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\patsy\\constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n",
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(df_train, df_test, df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'period', 'game-ver', 'lobby-mode', 'lobby', 'mode_1', 'mode_2',\n",
       "       'mode_3', 'mode_4', 'mode_5', 'stage_1', 'stage_2', 'stage_3',\n",
       "       'stage_4', 'stage_5', 'stage_6', 'stage_7', 'stage_8', 'stage_9',\n",
       "       'stage_10', 'stage_11', 'stage_12', 'stage_13', 'stage_14', 'stage_15',\n",
       "       'stage_16', 'stage_17', 'stage_18', 'stage_19', 'stage_20', 'stage_21',\n",
       "       'stage_22', 'stage_23', 'A1-weapon', 'A1-rank', 'A1-level', 'A2-weapon',\n",
       "       'A2-rank', 'A2-level', 'A3-weapon', 'A3-rank', 'A3-level', 'A4-weapon',\n",
       "       'A4-rank', 'A4-level', 'B1-weapon', 'B1-rank', 'B1-level', 'B2-weapon',\n",
       "       'B2-rank', 'B2-level', 'B3-weapon', 'B3-rank', 'B3-level', 'B4-weapon',\n",
       "       'B4-rank', 'B4-level', 'y', 'size', 'A-rank-ave', 'B-rank-ave',\n",
       "       'A-level-ave', 'B-level-ave'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>game-ver</th>\n",
       "      <th>lobby-mode</th>\n",
       "      <th>lobby</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>mode_2</th>\n",
       "      <th>mode_3</th>\n",
       "      <th>mode_4</th>\n",
       "      <th>mode_5</th>\n",
       "      <th>...</th>\n",
       "      <th>B3-level</th>\n",
       "      <th>B4-weapon</th>\n",
       "      <th>B4-rank</th>\n",
       "      <th>B4-level</th>\n",
       "      <th>y</th>\n",
       "      <th>size</th>\n",
       "      <th>A-rank-ave</th>\n",
       "      <th>B-rank-ave</th>\n",
       "      <th>A-level-ave</th>\n",
       "      <th>B-level-ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-15T20:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>sharp_neo</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>38.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-14T04:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>sputtery_clear</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-25T14:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>gachi</td>\n",
       "      <td>standard</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>dualsweeper_custom</td>\n",
       "      <td>8</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.75</td>\n",
       "      <td>128.50</td>\n",
       "      <td>124.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-11T14:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>194.0</td>\n",
       "      <td>hotblaster_custom</td>\n",
       "      <td>0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2237.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.25</td>\n",
       "      <td>261.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-14T06:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>gachi</td>\n",
       "      <td>standard</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>246.0</td>\n",
       "      <td>wakaba</td>\n",
       "      <td>12</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>138.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     period game-ver lobby-mode     lobby  mode_1  \\\n",
       "0   1  2019-10-15T20:00:00+00:00    5.0.1    regular  standard       1   \n",
       "1   2  2019-12-14T04:00:00+00:00    5.0.1    regular  standard       1   \n",
       "2   3  2019-12-25T14:00:00+00:00    5.0.1      gachi  standard       0   \n",
       "3   4  2019-11-11T14:00:00+00:00    5.0.1    regular  standard       1   \n",
       "4   5  2019-12-14T06:00:00+00:00    5.0.1      gachi  standard       0   \n",
       "\n",
       "   mode_2  mode_3  mode_4  mode_5  ...  B3-level           B4-weapon  B4-rank  \\\n",
       "0       0       0       0       0  ...      68.0           sharp_neo        0   \n",
       "1       0       0       0       0  ...     168.0      sputtery_clear        0   \n",
       "2       1       0       0       0  ...     160.0  dualsweeper_custom        8   \n",
       "3       0       0       0       0  ...     194.0   hotblaster_custom        0   \n",
       "4       1       0       0       0  ...     246.0              wakaba       12   \n",
       "\n",
       "   B4-level    y    size  A-rank-ave  B-rank-ave  A-level-ave  B-level-ave  \n",
       "0      31.0  1.0  2855.0        0.00        0.00        70.00        38.25  \n",
       "1     151.0  0.0  2391.0        0.00        0.00       149.00       130.00  \n",
       "2     126.0  0.0  2426.0        7.75        7.75       128.50       124.75  \n",
       "3     391.0  0.0  2237.4        0.00        0.00       174.25       261.75  \n",
       "4     160.0  1.0  2390.0       12.00       12.00       157.00       138.00  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146048"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weapon(data, weapondata):\n",
    "    weapons = [p + \"-weapon\" for p in players]\n",
    "    for weapon in weapons:\n",
    "        temp_weapon_detail = data[[weapon]].join(weapondata.set_index(\"key\"), on=weapon)\n",
    "        weapon_detail = [weapon[:3] + col for col in temp_weapon_detail.columns]\n",
    "        temp_weapon_detail.columns = weapon_detail\n",
    "        data = pd.concat([data, temp_weapon_detail], axis=1)\n",
    "        data = data.drop(weapon[:3] + weapon, axis=1)\n",
    "        data = data.drop(weapon[:3] + 'i', axis=1)\n",
    "        data = data.drop(weapon, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(data):\n",
    "    drop_col = [\"id\", \"period\", \"game-ver\", \"lobby-mode\", \"lobby\", ]\n",
    "    data = data.drop(drop_col, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nan(data):\n",
    "    data = data.fillna(0.0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_table(data, weapon, stagedata):\n",
    "    master_table = merge_weapon(data, weapon)\n",
    "    master_table = drop_column(master_table)\n",
    "    master_table = process_nan(master_table)\n",
    "    train = master_table.iloc[:len(target), :]\n",
    "    test = master_table.iloc[len(target):, :]\n",
    "    test = test.drop('y', axis=1)\n",
    "    train_x = train.drop('y', axis=1)\n",
    "    train_y = train['y']\n",
    "    target_encoder(train_x, train_y, test, te_cat_cols)\n",
    "    train_x = process_nan(train_x)\n",
    "    test = process_nan(test)\n",
    "    return train_x, train_y, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test = create_master_table(processed_data, processed_weapon, processed_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode_1           False\n",
       "mode_2           False\n",
       "mode_3           False\n",
       "mode_4           False\n",
       "mode_5           False\n",
       "stage_1          False\n",
       "stage_2          False\n",
       "stage_3          False\n",
       "stage_4          False\n",
       "stage_5          False\n",
       "stage_6          False\n",
       "stage_7          False\n",
       "stage_8          False\n",
       "stage_9          False\n",
       "stage_10         False\n",
       "stage_11         False\n",
       "stage_12         False\n",
       "stage_13         False\n",
       "stage_14         False\n",
       "stage_15         False\n",
       "stage_16         False\n",
       "stage_17         False\n",
       "stage_18         False\n",
       "stage_19         False\n",
       "stage_20         False\n",
       "stage_21         False\n",
       "stage_22         False\n",
       "stage_23         False\n",
       "A1-rank          False\n",
       "A1-level         False\n",
       "A2-rank          False\n",
       "A2-level         False\n",
       "A3-rank          False\n",
       "A3-level         False\n",
       "A4-rank          False\n",
       "A4-level         False\n",
       "B1-rank          False\n",
       "B1-level         False\n",
       "B2-rank          False\n",
       "B2-level         False\n",
       "B3-rank          False\n",
       "B3-level         False\n",
       "B4-rank          False\n",
       "B4-level         False\n",
       "size             False\n",
       "A-rank-ave       False\n",
       "B-rank-ave       False\n",
       "A-level-ave      False\n",
       "B-level-ave      False\n",
       "A1-subweapon     False\n",
       "A1-special       False\n",
       "A1-mainweapon    False\n",
       "A1-range         False\n",
       "A1-damage        False\n",
       "A1-rate          False\n",
       "A1-category      False\n",
       "A2-subweapon     False\n",
       "A2-special       False\n",
       "A2-mainweapon    False\n",
       "A2-range         False\n",
       "A2-damage        False\n",
       "A2-rate          False\n",
       "A2-category      False\n",
       "A3-subweapon     False\n",
       "A3-special       False\n",
       "A3-mainweapon    False\n",
       "A3-range         False\n",
       "A3-damage        False\n",
       "A3-rate          False\n",
       "A3-category      False\n",
       "A4-subweapon     False\n",
       "A4-special       False\n",
       "A4-mainweapon    False\n",
       "A4-range         False\n",
       "A4-damage        False\n",
       "A4-rate          False\n",
       "A4-category      False\n",
       "B1-subweapon     False\n",
       "B1-special       False\n",
       "B1-mainweapon    False\n",
       "B1-range         False\n",
       "B1-damage        False\n",
       "B1-rate          False\n",
       "B1-category      False\n",
       "B2-subweapon     False\n",
       "B2-special       False\n",
       "B2-mainweapon    False\n",
       "B2-range         False\n",
       "B2-damage        False\n",
       "B2-rate          False\n",
       "B2-category      False\n",
       "B3-subweapon     False\n",
       "B3-special       False\n",
       "B3-mainweapon    False\n",
       "B3-range         False\n",
       "B3-damage        False\n",
       "B3-rate          False\n",
       "B3-category      False\n",
       "B4-subweapon     False\n",
       "B4-special       False\n",
       "B4-mainweapon    False\n",
       "B4-range         False\n",
       "B4-damage        False\n",
       "B4-rate          False\n",
       "B4-category      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "train_x.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_iterations': 1000,\n",
    "    'early_stopping_rounds': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "[LightGBM] [Info] Number of positive: 55197, number of negative: 50740\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521036 -> initscore=0.084194\n",
      "[LightGBM] [Info] Start training from score 0.084194\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.65607\tvalid's binary_logloss: 0.680074\n",
      "[200]\ttrain's binary_logloss: 0.630949\tvalid's binary_logloss: 0.680545\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttrain's binary_logloss: 0.654799\tvalid's binary_logloss: 0.679744\n",
      "Fold : 1\n",
      "[LightGBM] [Info] Number of positive: 55080, number of negative: 50857\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519932 -> initscore=0.079769\n",
      "[LightGBM] [Info] Start training from score 0.079769\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655679\tvalid's binary_logloss: 0.681956\n",
      "[200]\ttrain's binary_logloss: 0.631135\tvalid's binary_logloss: 0.68266\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttrain's binary_logloss: 0.65436\tvalid's binary_logloss: 0.68186\n",
      "Fold : 2\n",
      "[LightGBM] [Info] Number of positive: 55152, number of negative: 50785\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520611 -> initscore=0.082492\n",
      "[LightGBM] [Info] Start training from score 0.082492\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.65611\tvalid's binary_logloss: 0.681258\n",
      "[200]\ttrain's binary_logloss: 0.631726\tvalid's binary_logloss: 0.680704\n",
      "[300]\ttrain's binary_logloss: 0.609059\tvalid's binary_logloss: 0.680722\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttrain's binary_logloss: 0.622211\tvalid's binary_logloss: 0.680389\n",
      "Fold : 3\n",
      "[LightGBM] [Info] Number of positive: 55111, number of negative: 50826\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6274\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520224 -> initscore=0.080941\n",
      "[LightGBM] [Info] Start training from score 0.080941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655632\tvalid's binary_logloss: 0.681799\n",
      "[200]\ttrain's binary_logloss: 0.631006\tvalid's binary_logloss: 0.681297\n",
      "[300]\ttrain's binary_logloss: 0.608276\tvalid's binary_logloss: 0.681897\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttrain's binary_logloss: 0.622662\tvalid's binary_logloss: 0.681067\n",
      "Fold : 4\n",
      "[LightGBM] [Info] Number of positive: 55177, number of negative: 50760\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520847 -> initscore=0.083438\n",
      "[LightGBM] [Info] Start training from score 0.083438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655686\tvalid's binary_logloss: 0.682338\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttrain's binary_logloss: 0.666696\tvalid's binary_logloss: 0.682263\n",
      "Fold : 5\n",
      "[LightGBM] [Info] Number of positive: 55231, number of negative: 50706\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6274\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521357 -> initscore=0.085480\n",
      "[LightGBM] [Info] Start training from score 0.085480\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655532\tvalid's binary_logloss: 0.683545\n",
      "[200]\ttrain's binary_logloss: 0.630737\tvalid's binary_logloss: 0.684059\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttrain's binary_logloss: 0.641809\tvalid's binary_logloss: 0.683222\n",
      "Fold : 6\n",
      "[LightGBM] [Info] Number of positive: 55290, number of negative: 50647\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521914 -> initscore=0.087712\n",
      "[LightGBM] [Info] Start training from score 0.087712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655067\tvalid's binary_logloss: 0.688197\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttrain's binary_logloss: 0.655342\tvalid's binary_logloss: 0.688159\n",
      "Fold : 7\n",
      "[LightGBM] [Info] Number of positive: 55163, number of negative: 50774\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520715 -> initscore=0.082908\n",
      "[LightGBM] [Info] Start training from score 0.082908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655459\tvalid's binary_logloss: 0.687056\n",
      "[200]\ttrain's binary_logloss: 0.631106\tvalid's binary_logloss: 0.687726\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttrain's binary_logloss: 0.642375\tvalid's binary_logloss: 0.686847\n",
      "Fold : 8\n",
      "[LightGBM] [Info] Number of positive: 55227, number of negative: 50711\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105938, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521314 -> initscore=0.085309\n",
      "[LightGBM] [Info] Start training from score 0.085309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655372\tvalid's binary_logloss: 0.68742\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttrain's binary_logloss: 0.665896\tvalid's binary_logloss: 0.686922\n",
      "Fold : 9\n",
      "[LightGBM] [Info] Number of positive: 55288, number of negative: 50650\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6275\n",
      "[LightGBM] [Info] Number of data points in the train set: 105938, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.521890 -> initscore=0.087617\n",
      "[LightGBM] [Info] Start training from score 0.087617\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655071\tvalid's binary_logloss: 0.688212\n",
      "[200]\ttrain's binary_logloss: 0.630233\tvalid's binary_logloss: 0.689087\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttrain's binary_logloss: 0.647859\tvalid's binary_logloss: 0.68794\n",
      "\n",
      "################################\n",
      "CV_score:0.5500219387725271\n"
     ]
    }
   ],
   "source": [
    "FOLD_NUM = 10\n",
    "kf = KFold(n_splits=FOLD_NUM, random_state=1234)\n",
    "\n",
    "scores = []\n",
    "\n",
    "pred_cv = np.zeros(len(test.index))\n",
    "\n",
    "num_round = 1000\n",
    "\n",
    "for i, (tdx, vdx) in enumerate(kf.split(train_x, train_y)):\n",
    "    print(f'Fold : {i}')\n",
    "    # 訓練用データと検証用データに分割\n",
    "    X_train, X_valid, y_train, y_valid = train_x.iloc[tdx], train_x.iloc[vdx], train_y.values[tdx], train_y.values[vdx]\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "    \n",
    "    # 学習の実行\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                      valid_names=[\"train\", \"valid\"], valid_sets=[lgb_train, lgb_valid],\n",
    "                      verbose_eval=100)\n",
    "\n",
    "    # 検証データに対する予測値を求めて、勝敗（０　or　１）に変換\n",
    "    va_pred = np.round(model.predict(X_valid,num_iteration=model.best_iteration))\n",
    "    \n",
    "    # accuracyスコアを計算\n",
    "    score_ = accuracy_score(y_valid, va_pred)\n",
    "    \n",
    "    # フォールド毎の検証時のスコアを格納\n",
    "    scores.append(score_)\n",
    "    \n",
    "    #テストデータに対する予測値を求める\n",
    "    submission = model.predict(test,num_iteration=model.best_iteration)\n",
    "    \n",
    "    #テストデータに対する予測値をフォールド数で割って蓄積\n",
    "    #(フォールド毎の予測値の平均値を求めることと同じ)\n",
    "    pred_cv += submission/FOLD_NUM\n",
    "\n",
    "# 最終的なテストデータに対する予測値を勝敗（０　or　１）に変換\n",
    "pred_cv = np.round(pred_cv)\n",
    "\n",
    "# 最終的なaccuracyスコアを平均値で出力\n",
    "print('')\n",
    "print('################################')\n",
    "print('CV_score:'+ str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用ファイルを作成する\n",
    "pd.DataFrame({\"id\": range(len(pred_cv)), \"y\": pred_cv }).to_csv(\"../data/07_model_output/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsplatoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
