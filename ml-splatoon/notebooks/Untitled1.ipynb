{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 16:11:22,351 - kedro.io.data_catalog - INFO - Loading data from `train` (CSVDataSet)...\n",
      "2020-10-03 16:11:22,542 - kedro.io.data_catalog - INFO - Loading data from `test` (CSVDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 16:11:22,631 - kedro.io.data_catalog - INFO - Loading data from `stagedata` (CSVDataSet)...\n",
      "2020-10-03 16:11:22,633 - kedro.io.data_catalog - INFO - Loading data from `weapon` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "df_train = catalog.load(\"train\")\n",
    "df_test = catalog.load(\"test\")\n",
    "df_stage = catalog.load(\"stagedata\")\n",
    "df_weapon = catalog.load(\"weapon\")\n",
    "\n",
    "\n",
    "players = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['mode', 'stage', 'A1-weapon', 'A2-weapon','A3-weapon','A4-weapon',\n",
    "          'B1-weapon', 'B2-weapon','B3-weapon','B4-weapon']\n",
    "te_cat_cols = ['A1-mainweapon', 'A1-subweapon', 'A1-special', 'A1-category',\n",
    "              'A2-mainweapon', 'A2-subweapon', 'A2-special', 'A2-category',\n",
    "              'A3-mainweapon', 'A3-subweapon', 'A3-special', 'A3-category',\n",
    "              'A4-mainweapon', 'A4-subweapon', 'A4-special', 'A4-category',\n",
    "              'B1-mainweapon', 'B1-subweapon', 'B1-special', 'B1-category',\n",
    "              'B2-mainweapon', 'B2-subweapon', 'B2-special', 'B2-category',\n",
    "              'B3-mainweapon', 'B3-subweapon', 'B3-special', 'B3-category',\n",
    "              'B4-mainweapon', 'B4-subweapon', 'B4-special', 'B4-category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disconnect_player_cnt(data):\n",
    "    temp_data = data.copy()\n",
    "    temp_data = temp_data.isnull()\n",
    "    data[\"A-disconnect\"] = temp_data[\"A1-weapon\"].astype(\"int\") + temp_data[\"A2-weapon\"].astype(\"int\") + temp_data[\"A3-weapon\"].astype(\"int\") + temp_data[\"A4-weapon\"].astype(\"int\")\n",
    "    data[\"A-connect\"] = 4 - data[\"A-disconnect\"]\n",
    "    data[\"B-disconnect\"] = temp_data[\"B1-weapon\"].astype(\"int\") + temp_data[\"B2-weapon\"].astype(\"int\") + temp_data[\"B3-weapon\"].astype(\"int\") + temp_data[\"B4-weapon\"].astype(\"int\")\n",
    "    data[\"B-connect\"] = 4 - data[\"B-disconnect\"]\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_to_value(x):\n",
    "    rank = {'c-': 2, 'c': 3, 'c+': 4,\n",
    "            'b-': 5, 'b': 6, 'b+': 7,\n",
    "            'a-': 8, 'a': 9, 'a+': 10,\n",
    "            's': 11, 's+': 12, 'x': 13\n",
    "            }\n",
    "    if x in rank:\n",
    "        x = rank[x]\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_rank(data):\n",
    "    players = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"lobby-mode\"] == \"regular\":\n",
    "            for player in players:\n",
    "                data.at[index, f\"{player}-rank\"] = 1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_average(data):\n",
    "    data[\"A-rank-ave\"] = (data[\"A1-rank\"] + data[\"A2-rank\"] + data[\"A3-rank\"] + data[\"A4-rank\"]) / data[\"A-connect\"]\n",
    "    data[\"B-rank-ave\"] = (data[\"B1-rank\"] + data[\"B2-rank\"] + data[\"B3-rank\"] + data[\"B4-rank\"]) / data[\"B-connect\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot_encoder(x):\n",
    "    import category_encoders as ce\n",
    "    list_cols = ['lobby-mode', 'mode', 'stage']\n",
    "    ce_ohe = ce.OneHotEncoder(cols=list_cols, handle_unknown='impute')\n",
    "    return ce_ohe.fit_transform(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(train_x, train_y, test_x, cat_cols):\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    for c in cat_cols:\n",
    "        data_tmp = pd.DataFrame({c: train_x[c], 'target': train_y})\n",
    "        target_mean = data_tmp.groupby(c)['target'].mean()\n",
    "        \n",
    "        test_x[c] = test_x[c].map(target_mean)\n",
    "        \n",
    "        tmp = np.repeat(np.nan, train_x.shape[0])\n",
    "        \n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=1234)\n",
    "        \n",
    "        for idx_1, idx_2 in kf.split(train_x):\n",
    "            target_mean = data_tmp.iloc[idx_1].groupby(c)['target'].mean()\n",
    "            tmp[idx_2] = train_x[c].iloc[idx_2].map(target_mean)\n",
    "        train_x[c] = tmp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def level_average(data):\n",
    "    data[\"A-level-ave\"] = (data[\"A1-level\"] + data[\"A2-level\"] + data[\"A3-level\"] + data[\"A4-level\"]) / data[\"A-connect\"]\n",
    "    data[\"B-level-ave\"] = (data[\"B1-level\"] + data[\"B2-level\"] + data[\"B3-level\"] + data[\"B4-level\"]) / data[\"B-connect\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(data):\n",
    "    import random\n",
    "    temp_data = data.copy()\n",
    "    temp_data = temp_data.dropna()\n",
    "    A_team = [\"A1\", \"A2\", \"A3\", \"A4\"]\n",
    "    B_team = [\"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "    for index, row in temp_data.iterrows():\n",
    "        rand_A = random.sample(A_team, 4)\n",
    "        temp_data.at[index,\"A1-weapon\"], temp_data.at[index,\"A2-weapon\"], temp_data.at[index,\"A3-weapon\"], temp_data.at[index,\"A4-weapon\"] = \\\n",
    "            row[f\"{rand_A[0]}-weapon\"], row[f\"{rand_A[1]}-weapon\"], row[f\"{rand_A[2]}-weapon\"], row[f\"{rand_A[3]}-weapon\"]\n",
    "        temp_data.at[index,\"A1-rank\"], temp_data.at[index,\"A2-rank\"], temp_data.at[index,\"A3-rank\"], temp_data.at[index,\"A4-rank\"] = \\\n",
    "            row[f\"{rand_A[0]}-rank\"], row[f\"{rand_A[1]}-rank\"], row[f\"{rand_A[2]}-rank\"], row[f\"{rand_A[3]}-rank\"]\n",
    "        temp_data.at[index,\"A1-level\"], temp_data.at[index,\"A2-level\"], temp_data.at[index,\"A3-level\"], temp_data.at[index,\"A4-level\"] = \\\n",
    "            row[f\"{rand_A[0]}-level\"], row[f\"{rand_A[1]}-level\"], row[f\"{rand_A[2]}-level\"], row[f\"{rand_A[3]}-level\"]\n",
    "\n",
    "        rand_B = random.sample(B_team, 4)\n",
    "        temp_data.at[index,\"B1-weapon\"], temp_data.at[index,\"B2-weapon\"], temp_data.at[index,\"B3-weapon\"], temp_data.at[index,\"B4-weapon\"] = \\\n",
    "            row[f\"{rand_B[0]}-weapon\"], row[f\"{rand_B[1]}-weapon\"], row[f\"{rand_B[2]}-weapon\"], row[f\"{rand_B[3]}-weapon\"]\n",
    "        temp_data.at[index,\"B1-rank\"], temp_data.at[index,\"B2-rank\"], temp_data.at[index,\"B3-rank\"], temp_data.at[index,\"B4-rank\"] = \\\n",
    "            row[f\"{rand_B[0]}-rank\"], row[f\"{rand_B[1]}-rank\"], row[f\"{rand_B[2]}-rank\"], row[f\"{rand_B[3]}-rank\"]\n",
    "        temp_data.at[index,\"B1-level\"], temp_data.at[index,\"B2-level\"], temp_data.at[index,\"B3-level\"], temp_data.at[index,\"B4-level\"] = \\\n",
    "            row[f\"{rand_B[0]}-level\"], row[f\"{rand_B[1]}-level\"], row[f\"{rand_B[2]}-level\"], row[f\"{rand_B[3]}-level\"]\n",
    "    data = pd.concat([data, temp_data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weapon(data, weapondata):\n",
    "    weapons = [p + \"-weapon\" for p in players]\n",
    "    for weapon in weapons:\n",
    "        temp_weapon_detail = data[[weapon]].join(weapondata.set_index(\"key\"), on=weapon)\n",
    "        weapon_detail = [weapon[:3] + col for col in temp_weapon_detail.columns]\n",
    "        temp_weapon_detail.columns = weapon_detail\n",
    "        data = pd.concat([data, temp_weapon_detail], axis=1)\n",
    "        data = data.drop(weapon[:3] + weapon, axis=1)\n",
    "        data = data.drop(weapon[:3] + 'i', axis=1)\n",
    "        data = data.drop(weapon, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_average(data):\n",
    "    data[\"A-range-ave\"] = (data[\"A1-range\"] + data[\"A2-range\"] + data[\"A3-range\"] + data[\"A4-range\"]) / data[\"A-connect\"]\n",
    "    data[\"B-range-ave\"] = (data[\"B1-range\"] + data[\"B2-range\"] + data[\"B3-range\"] + data[\"B4-range\"]) / data[\"B-connect\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_average(data):\n",
    "    data[\"A-damage-ave\"] = (data[\"A1-damage\"] + data[\"A2-damage\"] + data[\"A3-damage\"] + data[\"A4-damage\"]) / data[\"A-connect\"]\n",
    "    data[\"B-damage-ave\"] = (data[\"B1-damage\"] + data[\"B2-damage\"] + data[\"B3-damage\"] + data[\"B4-damage\"]) / data[\"B-connect\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_average(data):\n",
    "    data[\"A-rate-ave\"] = (data[\"A1-rate\"] + data[\"A2-rate\"] + data[\"A3-rate\"] + data[\"A4-rate\"]) / data[\"A-connect\"]\n",
    "    data[\"B-rate-ave\"] = (data[\"B1-rate\"] + data[\"B2-rate\"] + data[\"B3-rate\"] + data[\"B4-rate\"]) / data[\"B-connect\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weapon(weapon):\n",
    "    weapon[\"category\"] = weapon[\"category2\"]\n",
    "    weapon = weapon.drop([\"category1\", \"category2\"], axis=1)\n",
    "    return weapon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stage(stagedata):\n",
    "    return stagedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test, weapon, stagedata):\n",
    "    train = disconnect_player_cnt(train)\n",
    "    train = data_augmentation(train)\n",
    "    target = train['y']\n",
    "    test = disconnect_player_cnt(test)\n",
    "    data = pd.concat([train, test])\n",
    "    \n",
    "    # テーブルを結合\n",
    "    players = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\"]\n",
    "    data = data.join(stagedata.set_index(\"stage\"), on=\"stage\")\n",
    "    data = merge_weapon(data, weapon)\n",
    "    \n",
    "    for player in players:\n",
    "        data[f\"{player}-rank\"] = data[f\"{player}-rank\"].apply(rank_to_value)\n",
    "        data[f\"{player}-range\"] = data[f\"{player}-range\"].fillna(0)\n",
    "        data[f\"{player}-damage\"] = data[f\"{player}-damage\"].fillna(0)\n",
    "        data[f\"{player}-rate\"] = data[f\"{player}-rate\"].fillna(0)\n",
    "        data[f\"{player}-level\"] = data[f\"{player}-level\"].fillna(0)\n",
    "    data = regular_rank(data)\n",
    "    data = rank_average(data)\n",
    "    data = level_average(data)\n",
    "    data = range_average(data)\n",
    "    data = damage_average(data)\n",
    "    data = rate_average(data)\n",
    "    data = OneHot_encoder(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_augmentation(df_train)['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "processed_weapon = preprocess_weapon(df_weapon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stage = preprocess_stage(df_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\patsy\\constraint.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping\n",
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(df_train, df_test, processed_weapon, processed_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'period', 'game-ver', 'lobby-mode_1', 'lobby-mode_2', 'lobby',\n",
       "       'mode_1', 'mode_2', 'mode_3', 'mode_4',\n",
       "       ...\n",
       "       'A-rank-ave', 'B-rank-ave', 'A-level-ave', 'B-level-ave', 'A-range-ave',\n",
       "       'B-range-ave', 'A-damage-ave', 'B-damage-ave', 'A-rate-ave',\n",
       "       'B-rate-ave'],\n",
       "      dtype='object', length=122)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>game-ver</th>\n",
       "      <th>lobby-mode_1</th>\n",
       "      <th>lobby-mode_2</th>\n",
       "      <th>lobby</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>mode_2</th>\n",
       "      <th>mode_3</th>\n",
       "      <th>mode_4</th>\n",
       "      <th>...</th>\n",
       "      <th>A-rank-ave</th>\n",
       "      <th>B-rank-ave</th>\n",
       "      <th>A-level-ave</th>\n",
       "      <th>B-level-ave</th>\n",
       "      <th>A-range-ave</th>\n",
       "      <th>B-range-ave</th>\n",
       "      <th>A-damage-ave</th>\n",
       "      <th>B-damage-ave</th>\n",
       "      <th>A-rate-ave</th>\n",
       "      <th>B-rate-ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-15T20:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>38.25</td>\n",
       "      <td>39.00</td>\n",
       "      <td>41.25</td>\n",
       "      <td>65.75</td>\n",
       "      <td>51.0</td>\n",
       "      <td>78.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-14T04:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>59.25</td>\n",
       "      <td>49.00</td>\n",
       "      <td>51.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>62.50</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-25T14:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>standard</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>128.50</td>\n",
       "      <td>124.75</td>\n",
       "      <td>65.00</td>\n",
       "      <td>50.50</td>\n",
       "      <td>34.75</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.25</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-11T14:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>174.25</td>\n",
       "      <td>261.75</td>\n",
       "      <td>68.00</td>\n",
       "      <td>61.50</td>\n",
       "      <td>55.00</td>\n",
       "      <td>37.5</td>\n",
       "      <td>46.25</td>\n",
       "      <td>41.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-12-14T06:00:00+00:00</td>\n",
       "      <td>5.0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>standard</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>138.00</td>\n",
       "      <td>40.25</td>\n",
       "      <td>50.50</td>\n",
       "      <td>58.75</td>\n",
       "      <td>45.5</td>\n",
       "      <td>57.50</td>\n",
       "      <td>63.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     period game-ver  lobby-mode_1  lobby-mode_2  \\\n",
       "0   1  2019-10-15T20:00:00+00:00    5.0.1             1             0   \n",
       "1   2  2019-12-14T04:00:00+00:00    5.0.1             1             0   \n",
       "2   3  2019-12-25T14:00:00+00:00    5.0.1             0             1   \n",
       "3   4  2019-11-11T14:00:00+00:00    5.0.1             1             0   \n",
       "4   5  2019-12-14T06:00:00+00:00    5.0.1             0             1   \n",
       "\n",
       "      lobby  mode_1  mode_2  mode_3  mode_4  ...  A-rank-ave  B-rank-ave  \\\n",
       "0  standard       1       0       0       0  ...        1.00        1.00   \n",
       "1  standard       1       0       0       0  ...        1.00        1.00   \n",
       "2  standard       0       1       0       0  ...        8.75        8.75   \n",
       "3  standard       1       0       0       0  ...        1.00        1.00   \n",
       "4  standard       0       1       0       0  ...       13.00       13.00   \n",
       "\n",
       "   A-level-ave  B-level-ave  A-range-ave  B-range-ave  A-damage-ave  \\\n",
       "0        70.00        38.25        39.00        41.25         65.75   \n",
       "1       149.00       130.00        59.25        49.00         51.75   \n",
       "2       128.50       124.75        65.00        50.50         34.75   \n",
       "3       174.25       261.75        68.00        61.50         55.00   \n",
       "4       157.00       138.00        40.25        50.50         58.75   \n",
       "\n",
       "   B-damage-ave  A-rate-ave  B-rate-ave  \n",
       "0          51.0       78.75       68.75  \n",
       "1          56.0       62.50       75.00  \n",
       "2          39.0       56.25       60.00  \n",
       "3          37.5       46.25       41.25  \n",
       "4          45.5       57.50       63.50  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146048"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(data):\n",
    "    drop_col = [\"id\", \"period\", \"game-ver\", \"lobby\",\n",
    "               \"A1-range\", \"A2-range\", \"A3-range\", \"A4-range\", \n",
    "               \"B1-range\", \"B2-range\", \"B3-range\", \"B4-range\", \n",
    "               \"A1-damage\", \"A2-damage\", \"A3-damage\", \"A4-damage\", \n",
    "               \"B1-damage\", \"B2-damage\", \"B3-damage\", \"B4-damage\", \n",
    "               \"A1-rate\", \"A2-rate\", \"A3-rate\", \"A4-rate\", \n",
    "               \"B1-rate\", \"B2-rate\", \"B3-rate\", \"B4-rate\", ]\n",
    "    data = data.drop(drop_col, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nan(data):\n",
    "    data = data.fillna(0.0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_table(data):\n",
    "    master_table = drop_column(data)\n",
    "    master_table = process_nan(master_table)\n",
    "    train = master_table.iloc[:len(target), :]\n",
    "    test = master_table.iloc[len(target):, :]\n",
    "    test = test.drop('y', axis=1)\n",
    "    train_x = train.drop('y', axis=1)\n",
    "    train_y = train['y']\n",
    "    target_encoder(train_x, train_y, test, te_cat_cols)\n",
    "    train_x = process_nan(train_x)\n",
    "    test = process_nan(test)\n",
    "    return train_x, train_y, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test = create_master_table(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.to_csv(\"check_train_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lobby-mode_1</th>\n",
       "      <th>lobby-mode_2</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>mode_2</th>\n",
       "      <th>mode_3</th>\n",
       "      <th>mode_4</th>\n",
       "      <th>mode_5</th>\n",
       "      <th>stage_1</th>\n",
       "      <th>stage_2</th>\n",
       "      <th>stage_3</th>\n",
       "      <th>...</th>\n",
       "      <th>A-rank-ave</th>\n",
       "      <th>B-rank-ave</th>\n",
       "      <th>A-level-ave</th>\n",
       "      <th>B-level-ave</th>\n",
       "      <th>A-range-ave</th>\n",
       "      <th>B-range-ave</th>\n",
       "      <th>A-damage-ave</th>\n",
       "      <th>B-damage-ave</th>\n",
       "      <th>A-rate-ave</th>\n",
       "      <th>B-rate-ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>38.25</td>\n",
       "      <td>39.00</td>\n",
       "      <td>41.25</td>\n",
       "      <td>65.75</td>\n",
       "      <td>51.0</td>\n",
       "      <td>78.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>59.25</td>\n",
       "      <td>49.00</td>\n",
       "      <td>51.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>62.50</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>128.50</td>\n",
       "      <td>124.75</td>\n",
       "      <td>65.00</td>\n",
       "      <td>50.50</td>\n",
       "      <td>34.75</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.25</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>174.25</td>\n",
       "      <td>261.75</td>\n",
       "      <td>68.00</td>\n",
       "      <td>61.50</td>\n",
       "      <td>55.00</td>\n",
       "      <td>37.5</td>\n",
       "      <td>46.25</td>\n",
       "      <td>41.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>138.00</td>\n",
       "      <td>40.25</td>\n",
       "      <td>50.50</td>\n",
       "      <td>58.75</td>\n",
       "      <td>45.5</td>\n",
       "      <td>57.50</td>\n",
       "      <td>63.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lobby-mode_1  lobby-mode_2  mode_1  mode_2  mode_3  mode_4  mode_5  \\\n",
       "0             1             0       1       0       0       0       0   \n",
       "1             1             0       1       0       0       0       0   \n",
       "2             0             1       0       1       0       0       0   \n",
       "3             1             0       1       0       0       0       0   \n",
       "4             0             1       0       1       0       0       0   \n",
       "\n",
       "   stage_1  stage_2  stage_3  ...  A-rank-ave  B-rank-ave  A-level-ave  \\\n",
       "0        1        0        0  ...        1.00        1.00        70.00   \n",
       "1        0        1        0  ...        1.00        1.00       149.00   \n",
       "2        0        0        1  ...        8.75        8.75       128.50   \n",
       "3        0        0        0  ...        1.00        1.00       174.25   \n",
       "4        0        0        0  ...       13.00       13.00       157.00   \n",
       "\n",
       "   B-level-ave  A-range-ave  B-range-ave  A-damage-ave  B-damage-ave  \\\n",
       "0        38.25        39.00        41.25         65.75          51.0   \n",
       "1       130.00        59.25        49.00         51.75          56.0   \n",
       "2       124.75        65.00        50.50         34.75          39.0   \n",
       "3       261.75        68.00        61.50         55.00          37.5   \n",
       "4       138.00        40.25        50.50         58.75          45.5   \n",
       "\n",
       "   A-rate-ave  B-rate-ave  \n",
       "0       78.75       68.75  \n",
       "1       62.50       75.00  \n",
       "2       56.25       60.00  \n",
       "3       46.25       41.25  \n",
       "4       57.50       63.50  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_iterations': 1000,\n",
    "    'early_stopping_rounds': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 55191, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6881\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520979 -> initscore=0.083967\n",
      "[LightGBM] [Info] Start training from score 0.083967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655142\tvalid's binary_logloss: 0.682761\n",
      "[200]\ttrain's binary_logloss: 0.630195\tvalid's binary_logloss: 0.681809\n",
      "[300]\ttrain's binary_logloss: 0.608131\tvalid's binary_logloss: 0.681083\n",
      "[400]\ttrain's binary_logloss: 0.586524\tvalid's binary_logloss: 0.679864\n",
      "[500]\ttrain's binary_logloss: 0.566793\tvalid's binary_logloss: 0.679186\n",
      "[600]\ttrain's binary_logloss: 0.547862\tvalid's binary_logloss: 0.677965\n",
      "[700]\ttrain's binary_logloss: 0.529472\tvalid's binary_logloss: 0.677213\n",
      "[800]\ttrain's binary_logloss: 0.512395\tvalid's binary_logloss: 0.676361\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttrain's binary_logloss: 0.513874\tvalid's binary_logloss: 0.676095\n",
      "Fold : 1\n",
      "[LightGBM] [Info] Number of positive: 55191, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6882\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520979 -> initscore=0.083967\n",
      "[LightGBM] [Info] Start training from score 0.083967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655113\tvalid's binary_logloss: 0.682036\n",
      "[200]\ttrain's binary_logloss: 0.630066\tvalid's binary_logloss: 0.680896\n",
      "[300]\ttrain's binary_logloss: 0.607111\tvalid's binary_logloss: 0.679303\n",
      "[400]\ttrain's binary_logloss: 0.586067\tvalid's binary_logloss: 0.679046\n",
      "[500]\ttrain's binary_logloss: 0.566164\tvalid's binary_logloss: 0.679144\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttrain's binary_logloss: 0.58251\tvalid's binary_logloss: 0.678838\n",
      "Fold : 2\n",
      "[LightGBM] [Info] Number of positive: 55191, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6882\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520979 -> initscore=0.083967\n",
      "[LightGBM] [Info] Start training from score 0.083967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.654884\tvalid's binary_logloss: 0.68308\n",
      "[200]\ttrain's binary_logloss: 0.629653\tvalid's binary_logloss: 0.68136\n",
      "[300]\ttrain's binary_logloss: 0.606417\tvalid's binary_logloss: 0.680604\n",
      "[400]\ttrain's binary_logloss: 0.58553\tvalid's binary_logloss: 0.679204\n",
      "[500]\ttrain's binary_logloss: 0.565272\tvalid's binary_logloss: 0.678691\n",
      "[600]\ttrain's binary_logloss: 0.546171\tvalid's binary_logloss: 0.677746\n",
      "[700]\ttrain's binary_logloss: 0.527703\tvalid's binary_logloss: 0.677263\n",
      "[800]\ttrain's binary_logloss: 0.510752\tvalid's binary_logloss: 0.676479\n",
      "[900]\ttrain's binary_logloss: 0.494038\tvalid's binary_logloss: 0.676117\n",
      "[1000]\ttrain's binary_logloss: 0.478108\tvalid's binary_logloss: 0.675459\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's binary_logloss: 0.478108\tvalid's binary_logloss: 0.675459\n",
      "Fold : 3\n",
      "[LightGBM] [Info] Number of positive: 55191, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6879\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520979 -> initscore=0.083967\n",
      "[LightGBM] [Info] Start training from score 0.083967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655129\tvalid's binary_logloss: 0.684909\n",
      "[200]\ttrain's binary_logloss: 0.629722\tvalid's binary_logloss: 0.683329\n",
      "[300]\ttrain's binary_logloss: 0.607032\tvalid's binary_logloss: 0.682304\n",
      "[400]\ttrain's binary_logloss: 0.585703\tvalid's binary_logloss: 0.681369\n",
      "[500]\ttrain's binary_logloss: 0.566028\tvalid's binary_logloss: 0.681333\n",
      "Early stopping, best iteration is:\n",
      "[477]\ttrain's binary_logloss: 0.570261\tvalid's binary_logloss: 0.681099\n",
      "Fold : 4\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6879\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520989 -> initscore=0.084005\n",
      "[LightGBM] [Info] Start training from score 0.084005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.654641\tvalid's binary_logloss: 0.682964\n",
      "[200]\ttrain's binary_logloss: 0.629689\tvalid's binary_logloss: 0.682177\n",
      "[300]\ttrain's binary_logloss: 0.60622\tvalid's binary_logloss: 0.680834\n",
      "[400]\ttrain's binary_logloss: 0.585214\tvalid's binary_logloss: 0.680426\n",
      "[500]\ttrain's binary_logloss: 0.566394\tvalid's binary_logloss: 0.680639\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttrain's binary_logloss: 0.583545\tvalid's binary_logloss: 0.680298\n",
      "Fold : 5\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6879\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520989 -> initscore=0.084005\n",
      "[LightGBM] [Info] Start training from score 0.084005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.654366\tvalid's binary_logloss: 0.682775\n",
      "[200]\ttrain's binary_logloss: 0.629303\tvalid's binary_logloss: 0.681626\n",
      "[300]\ttrain's binary_logloss: 0.60646\tvalid's binary_logloss: 0.680731\n",
      "[400]\ttrain's binary_logloss: 0.585357\tvalid's binary_logloss: 0.680677\n",
      "[500]\ttrain's binary_logloss: 0.565575\tvalid's binary_logloss: 0.679314\n",
      "[600]\ttrain's binary_logloss: 0.546387\tvalid's binary_logloss: 0.678721\n",
      "[700]\ttrain's binary_logloss: 0.528146\tvalid's binary_logloss: 0.678746\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttrain's binary_logloss: 0.536516\tvalid's binary_logloss: 0.678502\n",
      "Fold : 6\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520989 -> initscore=0.084005\n",
      "[LightGBM] [Info] Start training from score 0.084005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655009\tvalid's binary_logloss: 0.682257\n",
      "[200]\ttrain's binary_logloss: 0.630209\tvalid's binary_logloss: 0.680852\n",
      "[300]\ttrain's binary_logloss: 0.607599\tvalid's binary_logloss: 0.679668\n",
      "[400]\ttrain's binary_logloss: 0.586481\tvalid's binary_logloss: 0.678155\n",
      "[500]\ttrain's binary_logloss: 0.566667\tvalid's binary_logloss: 0.677083\n",
      "[600]\ttrain's binary_logloss: 0.547615\tvalid's binary_logloss: 0.676729\n",
      "[700]\ttrain's binary_logloss: 0.529536\tvalid's binary_logloss: 0.675778\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttrain's binary_logloss: 0.530372\tvalid's binary_logloss: 0.675682\n",
      "Fold : 7\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6873\n",
      "[LightGBM] [Info] Number of data points in the train set: 105937, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520989 -> initscore=0.084005\n",
      "[LightGBM] [Info] Start training from score 0.084005\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's binary_logloss: 0.655139\tvalid's binary_logloss: 0.68321\n",
      "[200]\ttrain's binary_logloss: 0.630006\tvalid's binary_logloss: 0.682121\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttrain's binary_logloss: 0.631278\tvalid's binary_logloss: 0.682059\n",
      "Fold : 8\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6877\n",
      "[LightGBM] [Info] Number of data points in the train set: 105938, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520984 -> initscore=0.083985\n",
      "[LightGBM] [Info] Start training from score 0.083985\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.655422\tvalid's binary_logloss: 0.68209\n",
      "[200]\ttrain's binary_logloss: 0.630745\tvalid's binary_logloss: 0.682125\n",
      "Early stopping, best iteration is:\n",
      "[169]\ttrain's binary_logloss: 0.638405\tvalid's binary_logloss: 0.68144\n",
      "Fold : 9\n",
      "[LightGBM] [Info] Number of positive: 55192, number of negative: 50746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6873\n",
      "[LightGBM] [Info] Number of data points in the train set: 105938, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.520984 -> initscore=0.083985\n",
      "[LightGBM] [Info] Start training from score 0.083985\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's binary_logloss: 0.654978\tvalid's binary_logloss: 0.681382\n",
      "[200]\ttrain's binary_logloss: 0.630453\tvalid's binary_logloss: 0.680243\n",
      "[300]\ttrain's binary_logloss: 0.608285\tvalid's binary_logloss: 0.679678\n",
      "[400]\ttrain's binary_logloss: 0.587538\tvalid's binary_logloss: 0.679051\n",
      "[500]\ttrain's binary_logloss: 0.567574\tvalid's binary_logloss: 0.678162\n",
      "[600]\ttrain's binary_logloss: 0.549055\tvalid's binary_logloss: 0.678814\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttrain's binary_logloss: 0.558345\tvalid's binary_logloss: 0.678104\n",
      "\n",
      "################################\n",
      "CV_score:0.5647619146950944\n"
     ]
    }
   ],
   "source": [
    "FOLD_NUM = 10\n",
    "kf = StratifiedKFold(n_splits=FOLD_NUM, shuffle=True, random_state=1234)\n",
    "\n",
    "scores = []\n",
    "\n",
    "pred_cv = np.zeros(len(test.index))\n",
    "\n",
    "num_round = 1000\n",
    "\n",
    "for i, (tdx, vdx) in enumerate(kf.split(train_x, train_y)):\n",
    "    print(f'Fold : {i}')\n",
    "    # 訓練用データと検証用データに分割\n",
    "    X_train, X_valid, y_train, y_valid = train_x.iloc[tdx], train_x.iloc[vdx], train_y.values[tdx], train_y.values[vdx]\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "    \n",
    "    # 学習の実行\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=num_round,\n",
    "                      valid_names=[\"train\", \"valid\"], valid_sets=[lgb_train, lgb_valid],\n",
    "                      verbose_eval=100)\n",
    "\n",
    "    # 検証データに対する予測値を求めて、勝敗（０　or　１）に変換\n",
    "    va_pred = np.round(model.predict(X_valid,num_iteration=model.best_iteration))\n",
    "    \n",
    "    # accuracyスコアを計算\n",
    "    score_ = accuracy_score(y_valid, va_pred)\n",
    "    \n",
    "    # フォールド毎の検証時のスコアを格納\n",
    "    scores.append(score_)\n",
    "    \n",
    "    #テストデータに対する予測値を求める\n",
    "    submission = model.predict(test,num_iteration=model.best_iteration)\n",
    "    \n",
    "    #テストデータに対する予測値をフォールド数で割って蓄積\n",
    "    #(フォールド毎の予測値の平均値を求めることと同じ)\n",
    "    pred_cv += submission/FOLD_NUM\n",
    "\n",
    "# 最終的なテストデータに対する予測値を勝敗（０　or　１）に変換\n",
    "pred_cv = np.round(pred_cv)\n",
    "\n",
    "# 最終的なaccuracyスコアを平均値で出力\n",
    "print('')\n",
    "print('################################')\n",
    "print('CV_score:'+ str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valxa\\anaconda3\\envs\\splatoon-ml\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# 提出用ファイルを作成する\n",
    "pd.DataFrame({\"id\": range(len(pred_cv)), \"y\": pred_cv }).to_csv(\"../data/07_model_output/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsplatoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
